					PROMETHEUS ARCHITECTURE EXPLAINED

Source: https://www.youtube.com/watch?v=h4Sl21AKiDg&ab_channel=TechWorldwithNana

PROMETHEUS fue creado para monitorizar entornos de containerización altamente dinámicos,como kubernetes,docker-swarm,...
Sin embargo también puede monitorizar infraestructura no containerizada.
Prometheus se ha convertido en la herramienta nº 1 de monitorización en contenedores.

El despliegue moderno se ha vuelto muy complejo,puede haber cientos de procesos,todos interconectados.Esto es hoy en dia para un humano terriblemente dificil de mantener y debuggear,incluso a veces es simplemente imposible.

Imagina que un server se queda sin RAM y tira a un pod con la DB,un Deploy que necesite esa DB empezará a fallar,pero el usuario sólo verá un pequeño error por la UI.Desde aqui habría que ir hacia atrás y rezar por que lleguemos a la conclusión de que el servidor X se quedó sin RAM.

PROMETHEUS monitoriza constantemente todos los servicios.Alertará cuando algo crashee,mandando emails,por ejemplo.
Incluso puede identificar problemas antes de que ocurran(avisar cuando una cpu llegue al 70% de la RAM).

					PROMETHEUS ARCHITECTURE

El componente principal es el Prometheus Server,el cual hace el trabajo de monitorización.Consta de tres partes:
1- A Time Series Database: almacena todas las métricas(metrics data)

2- A Data Retrieval Worker: un worker que es responsable de pullear las métricas de aplicaciones,servicios,servidores.Tras pullearla la guarda en la DB del punto 1.

3- Un Web Server(bajo http): un web server que acepta PromQl Queries(un lenguaje de queries).Se le puede hacer queries bajo ese lenguaje sobre las métricas de la DB.También hay un dashboard web para interactuar o cualquier tipo de data visualization para interactuar(como Grafana)

IMPORTANTE: Prometheus puede monitorizar casi cualquier cosa.Estos objetos se les llama 'targets'.Según el tipo de 'target' se le podrá sacar especificas 'units'.
Por ejemplo a un Linux se le podrá sacar la unit para CPU Status,memory use,Disk Space,pero si es una aplicación se le podrá sacar otras métricas,como nº de peticiones,nº de excepciones

Prometheus guarda estas métricas en un formato legible para los humanos.
Cada métrica tendrá los atributos TYPE y HELP.HELP describe la métrica y TYPE tiene tres tipos:
1- Counter: cuantas veces ha sucedido
2- Gauge: medida o valor actual para algun parámetro(como la RAM,capacidad de disco).En definitiva un valor o medida.
3- Histograma: cuán grande o largo fue determinado hito

					COLLECTING METRICS FROM TARGETS

Prometheus coleciona mediante su worker datos de sus targets mediante peticiones HTTP.Por defecto es hostaddress/metrics.Y por ello cada target debe exponer este endpoint /metrics.Además,la data debe estar en el formato correcto para que Prometheus entienda 

IMPORTANTE: muchos servicios ya exponen el endpoint /metrics por defecto,pero muchos otros no tienen soporte nativo para Prometheus.Por ello necesitan de un componente que los ayude a exponer este endpoint.Para ello existe el componente Exporter

Exporter es un script o servicio que fetchea las metrics del target,las convierte al formato correcto y las expone en el endpoint /metrics.Prometheus tiene una lista oficial de exporters:
https://prometheus.io/docs/instrumenting/exporters/
Servicios como MySQL,Linux,todos ellos son scrapeables.Por ejemplo,el exporter de un Linux es un ejecutable que debo descargar,descomprimir y ejecutar.
Recolectará,formateará y expondrá las métricas para el worker de Prometheus.

NOTA: estos exporters también estan disponibles como Docker Images,con lo que muchas veces se crea el contenedor para el mysql y otro con el exporter,se conectan 

En cuanto a aplicaciones se necesitan client libraries.Aqui el link:
https://prometheus.io/docs/instrumenting/clientlibs/

				PROMETHEUS PULL - PUSH MODES

NOTA: Recuerda que Prometheus hace pull de la data,cargando él con la carga.Si fueran los microservicios los que tienen que mandarla,sería por push,y generarían mucho tráfico y high load network.Hacerlo por pull deja a los targets sin ninguna carga de trabajo por su parte.

Éste es el modo estandar de PROMETHEUS,hacerlo todo él.Sin embargo ciertos targets pueden ser 'short-lived job' como un cronjob,por ejemplo.En este caso puede ser el target el que mande la data,por pull,ya que el worker podría no tener tiempo para scrapear la data.Asi pues Prometheus combina las dos formas.
Sin embargo debe evitarse el push por todas las ventajas que permite el pull de la data.

						CONFIGURING PROMETHEUS

Bien,y como sabe prometheus qué scrapear y cuándo?.Mediante el file prometheus.yaml.En él definiré los targets y intervalos.Este es un ejemplo:

global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files: <-permiten agregar métricas o crear alertas para un hito
  # - "first.rules" 

scrape_configs:
  - job_name: prometheus
    static_configs:
      - targets: ['localhost:9090']

Esto es un ejemplo muy básico,en static_configs iría un arreglo de jobs(aqui sólo está el propio prometheus).Fijate que cada job puede sobreescribir los scrape_interval que arriba están en global.Esto suele ser asi ya que algunos jobs 15s puede ser muy poco tiempo o mucho,etc...
	
				PROMETHEUS AS ALERT MANAGER

Prometheus tiene un Alert Manager que puede avisar por Email,Slack,Watsap,.. por lo que se le configure.

NOTA: Prometheus puede almacenar la data de su DB tanto en local como el remoto.ESa data se guarda en un custom TimeSeries Format,con lo que no puedo guardarla en una db SQL

Recuerda que puedo usar PromQL para hacerle queries a Prometheus,o usar herramientas de visualization como Grafana.
Nana recalca que montar todo esto es muy complejo y no está bien documentado,asi que hará mas videos explicativos.

Por último Prometheus es totalmente compatible con Docker y puede ser fácilmente desplegado por ello

						SETTING UP PROMETHEUS PART ONE

Source: https://www.youtube.com/watch?v=QoDqxm7ybLc

Hay varias formas de desplegar Prometheus.
1- Crear todos los yaml yo mismo y aplicarlos en el orden correcto(obviamente no es lo que se hace ya)
2- Usando un 'operator'.Es como un manager que controlará todos los componentes de Prometheus.Controlará todo como una unidad
3- Usando un Helm Chart para desplegar el operador.Helm creará el initial Setup y despues el Operator lo manejará.

								OPERATORS 
Source: https://www.youtube.com/watch?v=ha3LjlD6g7g&ab_channel=TechWorldwithNana

NOTA: los Operator son usados en Stateful Applications.Cabe destacar que hay que diferenciar entre una Stateful App Without Operator y una Stateful App with Operator.

1- Stateful App Without operator: una Stateful App necesitará programadores que 'operen' en la app,ya que va a tener problemas por ser una Stateful App (App Without Operator,nosotros somos el operador)	

2- Stateful App With Operator: si bien se aconseja que la DB use almacenamiento externo(en definitiva desacoplarla del cluster) no siempre será posible esto,y hay que manejar una Stateful App.

IMPORTANTE: Un operator reemplaza al 'operador humano' con software.Cualquier tarea la hará ahora el programa.Sabrá como desplegar la app,crear replicas,recuperarse de un error.De esta forma,el operador hace sencillo escalar una Stateful App.

Más concretamente,el operador es como un 'custom control-loop' que estará mirando por el proceso,de igual forma que lo hace Kubernetes.
Usa CRDs o Custom Resource Definitions(componentes customizados de Kubernetes,que extenderán de la k8s API,siendo totalmente compatibles y reemplazables).Yo también puedo crear un CRD.
También tendrá todo lo que tiene la parte que sustituye(acceso a configMaps,Secrets,Services,..)
En resumen k8s es capaz de automatizar todo el lifecycle de una Stateless App,mientras que si es Stateful tengo que usar un operador o hacerlo yo,ya que k8s no es capaz
NOTA: cada aplicación tendrá su operador(prometheus-operator,mysql-operator,postgres-operator).
Los operators son creados normalmente por equipos con conocimientos TOP en ese tema.Puedo verlos en OperatorHub.io y si quiero crearlos tengo el operator SDK para desarrollarlo y publicarlo:

				DESPLEGANDO PROMETHEUS WITH HELM + PROMETHEUS

NOTA: recuerda que helm se instala con brew y está escrito en Go por motivos obvios.Una vez instalado helm instalo el operator:
>helm install prometheus stable/prometheus-operator
Seguir por la instalación mañana

IMPORTANTE: ha cambiado la instalación,ahora es con un helm Chart:
https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack
>helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
>helm repo update
$ helm install [RELEASE_NAME] prometheus-community/kube-prometheus-stack

PAra desinstalar
$ helm uninstall [RELEASE_NAME]
* CRDs created by this chart are not removed by default and should be manually cleaned up:

kubectl delete crd alertmanagerconfigs.monitoring.coreos.com
kubectl delete crd alertmanagers.monitoring.coreos.com
kubectl delete crd podmonitors.monitoring.coreos.com
kubectl delete crd probes.monitoring.coreos.com
kubectl delete crd prometheuses.monitoring.coreos.com
kubectl delete crd prometheusrules.monitoring.coreos.com
kubectl delete crd servicemonitors.monitoring.coreos.com
kubectl delete crd thanosrulers.monitoring.coreos.com

						QUE ES LO QUE HE INSTALADO

Puedo ver que crea 6 pods,8 Services,3 Deployment 3 replicaSet,2 StatefulSet..

Empezaremos por los StatefulSet,pues son lo más importante:
NAME                                                                    READY   AGE
statefulset.apps/alertmanager-prometheus-kube-prometheus-alertmanager   1/1     89s
statefulset.apps/prometheus-prometheus-kube-prometheus-prometheus       1/1     89s

El segundo es prometheus en si mismo,manejado por el operador.El primero es el alertManager,encargado de las alertas.

En cuanto a los deployments,veré tres,de nuevo el core de prometheus gestionado por el operador tiene uno,el otro es para Grafana y el otro es para métricas.Scraperará el cluster,lo cual es muy útil pues me monitoriza la infraestructura actual del cluster donde despliegue Prometheus:

deployment.apps/prometheus-grafana                    1/1     1            1           92s
deployment.apps/prometheus-kube-prometheus-operator   1/1     1            1           92s
deployment.apps/prometheus-kube-state-metrics         1/1     1            1           92s

También puedo ver un DaemonSet.Un DaemonSet es un componente que se ejecuta en cada Worker Node(es un feature principal).Este DaemonSet traduce las métricas de los Worker Nodes a Prometheus Metrics.

Los Pods obviamente vienen creados por los Deployments y los StatefulSets en cuanto a los Services simplemente darán la conectividad necesaria.
NOTA:puedo ver que algunos pods están replicados

IMPORTANTE: al instalar esto con el operator ya he configurado el cluster para monitorización,asi que desde ya puedo analizar todo esto.Si miro los configMaps veré 15 o 20(casi todos creados por el operator):
kube-root-ca.crt                                               1      6d19h
mongodb-configmap                                              1      5d16h
prometheus-grafana                                             1      16m
prometheus-grafana-config-dashboards                           1      16m
prometheus-grafana-test                                        1      16m
prometheus-kube-prometheus-alertmanager-overview               1      16m
prometheus-kube-prometheus-apiserver                           1      16m
prometheus-kube-prometheus-cluster-total                       1      16m
prometheus-kube-prometheus-controller-manager                  1      16m
prometheus-kube-prometheus-etcd                                1      16m
prometheus-kube-prometheus-grafana-datasource                  1      16m
prometheus-kube-prometheus-k8s-coredns                         1      16m
prometheus-kube-prometheus-k8s-resources-cluster               1      16m
prometheus-kube-prometheus-k8s-resources-namespace             1      16m
prometheus-kube-prometheus-k8s-resources-node                  1      16m
prometheus-kube-prometheus-k8s-resources-pod                   1      16m
prometheus-kube-prometheus-k8s-resources-workload              1      16m
prometheus-kube-prometheus-k8s-resources-workloads-namespace   1      16m
prometheus-kube-prometheus-kubelet                             1      16m
prometheus-kube-prometheus-namespace-by-pod                    1      16m
prometheus-kube-prometheus-namespace-by-workload               1      16m
prometheus-kube-prometheus-node-cluster-rsrc-use               1      16m
prometheus-kube-prometheus-node-rsrc-use                       1      16m
prometheus-kube-prometheus-nodes                               1      16m
prometheus-kube-prometheus-persistentvolumesusage              1      16m
prometheus-kube-prometheus-pod-total                           1      16m
prometheus-kube-prometheus-prometheus                          1      16m
prometheus-kube-prometheus-proxy                               1      16m
prometheus-kube-prometheus-scheduler                           1      16m
prometheus-kube-prometheus-statefulset                         1      16m
prometheus-kube-prometheus-workload-total                      1      16m

Lo mismo para los Secrets.Obviamente configurar esto manualmente es inviable.
NOTA: otros recursos que se han creado son los CRDs.CRD stands for Custom Resource Definitions:
oscar@acer-linux:~$ k get crd -o wide
NAME                                        CREATED AT
alertmanagerconfigs.monitoring.coreos.com   2022-02-06T13:14:06Z
alertmanagers.monitoring.coreos.com         2022-02-06T13:14:06Z
podmonitors.monitoring.coreos.com           2022-02-06T13:14:06Z
probes.monitoring.coreos.com                2022-02-06T13:14:06Z
prometheuses.monitoring.coreos.com          2022-02-06T13:14:06Z
prometheusrules.monitoring.coreos.com       2022-02-06T13:14:06Z
servicemonitors.monitoring.coreos.com       2022-02-06T13:14:06Z
thanosrulers.monitoring.coreos.com          2022-02-06T13:14:06Z

Puedo ver más de cerca que ha creado el statefulset guardando su description a un file temporalmente:
 k describe statefulset prometheus-prometheus-kube-prometheus-prometheus > prom.yaml
Y lo mismo para el deployment del operator,que es muy interesante:
k describe deployment <name> > operator.yaml
Si leo este file veré que es el orquestador de todo el stack,lo cual es lógico pues es el operator.
Lo importante de todo lo que dice Nana es entender como agregar o editar alert rules y como ajustar la configuración de Prometheus(añadir nuevos endpoints para que scrapee)

							ACCESING GRAFANA UI 

Si miro los servicios veré que es un ClusterIP,asi que está cerrado.Vamos a hacer un port-forward:
>kubectl get deployments
prometheus-grafana                    1/1     1            1           39m
>k get pods
prometheus-grafana-f4796bddc-pdbvs                       3/3     Running   0   

Fijate que hay 3,asi que tengo que decirle cual(con la flag -c de choose):

oscar@acer-linux:~$ k logs prometheus-grafana-f4796bddc-pdbvs 
error: a container name must be specified for pod prometheus-grafana-f4796bddc-pdbvs, choose one of: [grafana-sc-dashboard grafana-sc-datasources grafana]

>k logs prometheus-grafana-f4796bddc-pdbvs -c grafana 
Hay que coger el grafana.Alli veré que el user es 'admin' y el port el 3000

t=2022-02-06T13:14:21+0000 lvl=info msg="Created default admin" logger=sqlstore user=admin
t=2022-02-06T13:14:21+0000 lvl=info msg="Created default organization" logger=sqlstore
t=2022-02-06T13:14:21+0000 lvl=info msg="Initialising plugins" logger=plugin.manager
t=2022-02-06T13:14:21+0000 lvl=info msg="Plugin registered" logger=plugin.manager pluginId=input
t=2022-02-06T13:14:21+0000 lvl=info msg="Live Push Gateway initialization" logger=live.push_http
t=2022-02-06T13:14:21+0000 lvl=info msg="HTTP Server Listen" logger=http.server address=[::]:3000 protocol=http subUrl= socket=

Ahora que ya sé que quiero forwardear el puerto 3000 del pod hacia afuera tipeo:
k port-forward deployment/<name> 3000 <- esto abre el 3000 del pod.

NOTA:el usuario será admin y la password 'prom-operator'
Fijate que podré ver métricas como la CPU,la RAM,la bandwidth de cada pod,nodo,por namespace,etc...

						PROMETHEUS UI

Aparte de Grafana UI Prometheus también tiene otra UI accesible de igual manera mediante port-forward:
 k port-forward prometheus-prometheus-kube-prometheus-prometheus-0 9090

Prometheus UI puede ser interesante también en determinadas ocasiones.
Resumen: hemos visto como desplegar Prometheus usando Helm + operator.Hemos visto una brief overview de todo lo que instala y hemos visto como acceder a las UIs de monitorización mediante port-forward.

		PARTE DOS STEPS TO MONITOR THIRD-PARTY APPS USING PROMETHEUS EXPORTER

Source: https://www.youtube.com/watch?v=mLPg49b33sA&ab_channel=TechWorldwithNana

Antes que nada crearemos otro cluster mas grande.Haremos el despliegue de un MongoDB y de un MongoDB Exporter para que exponga las métricas.

Despues habrá que permitir que PROMETHEUS las haga pull,para ello usaremos otro componente llamado ServiceMonitor.

Iremos poco a poco,viendo cada paso en Prometheus UI y Grafana UI.
Para crear otro cluster es con -p <clustername>(la p es de profile):
>minikube start --nodes 2 --cpus 4 --memory 8192 -p multinode <- creará otro cluster llamado multinode con dos nodos,4cpus y 8GB de RAM
NOTA:fijate que ahora para habilitar addons tengo que usar -p también:
>minikube addons list <- ojo,solo muestra para el cluster por defecto
> minikube addons -p multinode list <- 

Fijate que cada profile es un cluster.Bien una vez iniciado un cluster con más recursos,ya que Prometheus usa un montón de componentes,puedo continuar.

>helm ls <- puedo ver lo instalado con helm con ls

Lo primero será exponer a Prometheus UI(fijate que el service ya me dice el puerto,asinto):
prometheus-kube-prometheus-prometheus     10.244.1.8:9090                                   3m14s
Luego:
k port-forward service/<svc_name> 9090:9090

En Prometheus UI puedo hacer click en status/targets y ver los targets actuales que está scrapeando.

* Puedo ver los servicemonitor a los que se está escrapeando con k get servicemonitor.Es un custom component.

$ k get servicemonitor
NAME                                                 AGE
prometheus-grafana                                   11m
prometheus-kube-prometheus-alertmanager              11m
prometheus-kube-prometheus-apiserver                 11m
prometheus-kube-prometheus-coredns                   11m
prometheus-kube-prometheus-kube-controller-manager   11m
prometheus-kube-prometheus-kube-etcd                 11m
prometheus-kube-prometheus-kube-proxy                11m
prometheus-kube-prometheus-kube-scheduler            11m
prometheus-kube-prometheus-kubelet                   11m
prometheus-kube-prometheus-operator                  11m
prometheus-kube-prometheus-prometheus                11m
prometheus-kube-state-metrics                        11m
prometheus-prometheus-node-exporter                  11m


Veamos el yaml de uno de ellos:
k get servicemonitor -o wide <servicemonitor> -o yaml > file.yaml

Puedo ver la apiVersion y el kind:
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
O que expone /metrics:
    path: /metrics
    port: http-web
    scheme: http
    scrapeTimeout: 30s

NOTA: hay una prop muy importante que es metadata.labels.release: prometheus.Permite a Prometheus descubrir el servicemonitor en el cluster y registrarlo para escrapearlo.
Prometheus creará un crd.Si hace match con algun ServiceMonitor lo escrapeará.

				CREATING  MONGODB DEPLOY + SRV

Copio de su Gitlab el yaml:
https://gitlab.com/nanuchi/youtube-tutorial-series/-/blob/master/prometheus-exporter/mongodb.yaml
Hora de desplegar el exporter

NOTA:cada aplicación tiene su propio exporter.Recuerda que el exporter hace dos cosas,colecciona las métricas y las convierte al formato adecuado para Prometheus y la segunda es que expone el endpoint /metrics

Perfectamente puede ser un deployment separado en el mismo cluster,lo cual es bastante cómodo,pues cuando me canse de él simplemente borro el deployment.

IMPORTANTE:puedp ver ya un pod con un exporter,que es el que está exponiendo el cluster actual ya.
prometheus-prometheus-node-exporter-7xm4t                1/1     Running   0          31m <- éste!

IMPORTANTE: los exporters también están como Docker Images,lo cual va a ser más comodo que usar ese repositorio.Busco por mongodb-exporter y veré el de bitnami que parece muy reliable.

					COMPONENTS OF A EXPORTER

Un exporter tiene tres componentes,la aplicación en sí,un Service para conectar con el Exporter y un ServiceMonitor,que recordemos que era un componente para poder ser descubierto por un crd.
En resumen,puedo crear un file con estos tre componentes(Deployment + Service + SrviceMonitor) o puedo buscar por un Helm Chart que ya tenga esto configurado

Busco por mongodb-exporter helm chart y llegaré al repo oficial:
Me pide esto
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts

NOTA: recuerda que para poder sobreescribir parametros en un helm chart tengo que sar los 'helm parameters'.Puedo usar el comando <helm show values [chart name]> para ver las variables que puedo usar en una helm chart

>helm show values prometheus-community/prometheus-mongodb-exporter

Recuerda que los puedo guardar a un file temporal,de echo es lo que debí haber echo:
>helm show values prometheus-community/prometheus-mongodb-exporter > temp.yaml

Ahora hay un par de cosas que hay que cambiar.La MongoURI viene vacia en nuestro caso sera mongodb://<serviceName>:27017.Y aparte habia que añadir la label 'release: prometheus' para que Prometheus descubra nuevos ServiceMonitor en el cluster.Recuerda que cuando suceda eso creará un nuevo crd.
Obviamente nos dan la helm chart limpia en este sentido.
Al final quedará así:

mongodb:
  uri: "mongodb://mongodb-service:27017"

serviceMonitor:
  additionalLabels: 
    release: prometheus

Ya puedo instalarlo,pero ojo que va con el file anterior:
helm install <release name> <chartname> -f file.yaml (release name el que quiera)

Puedo ver un nuevo helm chart con <helm ls> y un nuevo pod,un nuevo service y un nuevo servicemonitor:
NAME                                                 AGE
mongodb-exporter-prometheus-mongodb-exporter         106s <- es el servicemonitor
Si le saco el yaml veré la label(recuerda que sabo el yaml con get resource <resource_name> -o yaml):
  release: prometheus <- viene del file
Puedo hacer un port-forward del service a ver que veo en /metrics(veo las métricas en el formato ese)
Y si voy a Prometheus UI veré un nuevo endpoint: serviceMonitor/default/mongodb-exporter-prometheus-mongodb-exporter/0 (1/1 up)
NOTA:fijate que no se creó un crd,no es así,no era importante esto
Por último lo veremos en Grafana,que además es la UI que más se usa.
*hago el portforward...
Desde luego mi conocimento de Kubernetes ha subido mucho.


 





